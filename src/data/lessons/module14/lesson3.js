const lesson3 = {
  id: '14-3',
  title: 'Migrations et Gestion des Donn√©es en Production',
  description:
    'Strat√©gies avanc√©es pour g√©rer les migrations de base de donn√©es, la sauvegarde, et la synchronisation des donn√©es en production.',
  difficulty: 'expert',
  duration: 50,
  tags: [
    'Next.js',
    'Migrations',
    'Production',
    'Sauvegarde',
    'Synchronisation'
  ],
  prerequisites: ['module14-lesson1', 'module14-lesson2'],

  content: {
    theory: `
      <h2>üîß Migrations et Gestion des Donn√©es en Production</h2>
      
      <h3>1. Strat√©gies de Migration</h3>
      <p>Approches pour g√©rer les changements de sch√©ma en production de mani√®re s√ªre.</p>
      
      <div class="code-example">
        <pre><code>// scripts/migration-manager.js
import { execSync } from 'child_process'
import prisma from '../lib/prisma'

export class MigrationManager {
  static async createMigration(name, description) {
    const timestamp = new Date().toISOString().replace(/[:.]/g, '-')
    const migrationName = \`\${timestamp}-\${name}\`
    
    try {
      // Cr√©er la migration
      execSync(\`npx prisma migrate dev --name \${migrationName} --create-only\`, {
        stdio: 'inherit'
      })
      
      console.log(\`Migration cr√©√©e: \${migrationName}\`)
      
      // Logger la migration
      await this.logMigration(migrationName, description, 'created')
      
    } catch (error) {
      console.error('Erreur lors de la cr√©ation de migration:', error)
      throw error
    }
  }
  
  static async deployMigration(environment = 'production') {
    try {
      // V√©rifier l'√©tat actuel
      const status = await this.checkMigrationStatus()
      console.log('√âtat des migrations:', status)
      
      if (environment === 'production') {
        // Backup avant migration en production
        await this.createBackup()
      }
      
      // D√©ployer les migrations
      execSync('npx prisma migrate deploy', {
        stdio: 'inherit',
        env: { ...process.env, NODE_ENV: environment }
      })
      
      await this.logMigration('deploy', 'Migration deployed', 'completed')
      console.log('Migrations d√©ploy√©es avec succ√®s')
      
    } catch (error) {
      console.error('Erreur lors du d√©ploiement:', error)
      
      if (environment === 'production') {
        console.log('Tentative de rollback...')
        await this.rollbackMigration()
      }
      
      throw error
    }
  }
  
  static async rollbackMigration() {
    try {
      // Restaurer depuis la sauvegarde
      await this.restoreBackup()
      console.log('Rollback effectu√© avec succ√®s')
      
    } catch (error) {
      console.error('Erreur lors du rollback:', error)
      throw error
    }
  }
  
  static async logMigration(name, description, status) {
    return await prisma.migration_log.create({
      data: {
        name,
        description,
        status,
        executed_at: new Date(),
        environment: process.env.NODE_ENV || 'development'
      }
    })
  }
}</code></pre>
      </div>
      
      <h3>2. Syst√®me de Sauvegarde Automatique</h3>
      <p>Implementation d'un syst√®me de sauvegarde robuste avec rotation.</p>
      
      <div class="code-example">
        <pre><code>// scripts/backup-manager.js
import { S3Client, PutObjectCommand, ListObjectsV2Command } from '@aws-sdk/client-s3'
import { execSync } from 'child_process'
import fs from 'fs'
import path from 'path'
import cron from 'node-cron'

export class BackupManager {
  constructor() {
    this.s3Client = new S3Client({
      region: process.env.AWS_REGION,
      credentials: {
        accessKeyId: process.env.AWS_ACCESS_KEY_ID,
        secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY
      }
    })
    this.bucketName = process.env.BACKUP_BUCKET_NAME
  }
  
  async createDatabaseBackup() {
    const timestamp = new Date().toISOString().replace(/[:.]/g, '-')
    const filename = \`backup-\${timestamp}.sql\`
    const filepath = path.join('/tmp', filename)
    
    try {
      // Cr√©er le dump PostgreSQL
      const dumpCommand = \`pg_dump \${process.env.DATABASE_URL} > \${filepath}\`
      execSync(dumpCommand, { stdio: 'inherit' })
      
      // Compresser le fichier
      const compressedFile = \`\${filepath}.gz\`
      execSync(\`gzip \${filepath}\`)
      
      // Upload vers S3
      const fileBuffer = fs.readFileSync(compressedFile)
      
      await this.s3Client.send(new PutObjectCommand({
        Bucket: this.bucketName,
        Key: \`database-backups/\${filename}.gz\`,
        Body: fileBuffer,
        Metadata: {
          created_at: new Date().toISOString(),
          database: 'main',
          environment: process.env.NODE_ENV
        }
      }))
      
      // Nettoyer le fichier local
      fs.unlinkSync(compressedFile)
      
      console.log(\`Sauvegarde cr√©√©e: \${filename}.gz\`)
      
      // Rotation des sauvegardes anciennes
      await this.rotateBackups()
      
      return \`database-backups/\${filename}.gz\`
      
    } catch (error) {
      console.error('Erreur lors de la sauvegarde:', error)
      throw error
    }
  }
  
  async rotateBackups(retentionDays = 30) {
    try {
      const response = await this.s3Client.send(new ListObjectsV2Command({
        Bucket: this.bucketName,
        Prefix: 'database-backups/'
      }))
      
      const cutoffDate = new Date()
      cutoffDate.setDate(cutoffDate.getDate() - retentionDays)
      
      const oldBackups = response.Contents?.filter(object => 
        object.LastModified < cutoffDate
      ) || []
      
      for (const backup of oldBackups) {
        await this.s3Client.send(new DeleteObjectCommand({
          Bucket: this.bucketName,
          Key: backup.Key
        }))
        console.log(\`Sauvegarde supprim√©e: \${backup.Key}\`)
      }
      
    } catch (error) {
      console.error('Erreur lors de la rotation:', error)
    }
  }
  
  setupScheduledBackups() {
    // Sauvegarde quotidienne √† 2h du matin
    cron.schedule('0 2 * * *', () => {
      console.log('D√©but de la sauvegarde programm√©e...')
      this.createDatabaseBackup()
        .then(() => console.log('Sauvegarde programm√©e termin√©e'))
        .catch(err => console.error('Erreur sauvegarde programm√©e:', err))
    })
    
    // Sauvegarde hebdomadaire compl√®te le dimanche √† 1h
    cron.schedule('0 1 * * 0', () => {
      console.log('D√©but de la sauvegarde hebdomadaire...')
      this.createFullBackup()
        .then(() => console.log('Sauvegarde hebdomadaire termin√©e'))
        .catch(err => console.error('Erreur sauvegarde hebdomadaire:', err))
    })
  }
}</code></pre>
      </div>
      
      <h3>3. Synchronisation de Donn√©es Multi-Environnements</h3>
      <p>Outils pour synchroniser les donn√©es entre d√©veloppement, staging et production.</p>
      
      <div class="code-example">
        <pre><code>// scripts/data-sync.js
import prisma from '../lib/prisma'

export class DataSynchronizer {
  static async syncUserData(fromEnv, toEnv, options = {}) {
    const { 
      includePasswords = false, 
      anonymize = true,
      batchSize = 1000 
    } = options
    
    try {
      console.log(\`Synchronisation des utilisateurs: \${fromEnv} ‚Üí \${toEnv}\`)
      
      // Connexions aux diff√©rents environnements
      const sourceDb = this.getConnection(fromEnv)
      const targetDb = this.getConnection(toEnv)
      
      // R√©cup√©rer les utilisateurs par batch
      let offset = 0
      let hasMore = true
      
      while (hasMore) {
        const users = await sourceDb.user.findMany({
          skip: offset,
          take: batchSize,
          select: {
            id: true,
            email: true,
            name: true,
            avatar: true,
            role: true,
            createdAt: true,
            ...(includePasswords && { password: true })
          }
        })
        
        if (users.length === 0) {
          hasMore = false
          break
        }
        
        // Anonymiser si n√©cessaire
        const processedUsers = anonymize ? 
          this.anonymizeUsers(users) : users
        
        // Ins√©rer en batch avec gestion des conflits
        await this.upsertUsers(targetDb, processedUsers)
        
        offset += batchSize
        console.log(\`Synchronis√©s: \${offset} utilisateurs\`)
      }
      
      console.log('Synchronisation termin√©e')
      
    } catch (error) {
      console.error('Erreur de synchronisation:', error)
      throw error
    }
  }
  
  static anonymizeUsers(users) {
    return users.map((user, index) => ({
      ...user,
      email: \`user\${index + 1}@example.com\`,
      name: \`User \${index + 1}\`,
      avatar: null,
      password: undefined // Retirer le mot de passe
    }))
  }
  
  static async upsertUsers(db, users) {
    for (const user of users) {
      await db.user.upsert({
        where: { id: user.id },
        update: {
          email: user.email,
          name: user.name,
          avatar: user.avatar,
          role: user.role
        },
        create: user
      })
    }
  }
  
  static async syncPostsData(fromEnv, toEnv, options = {}) {
    const { includeUnpublished = false, limitPerUser = 10 } = options
    
    const sourceDb = this.getConnection(fromEnv)
    const targetDb = this.getConnection(toEnv)
    
    try {
      const posts = await sourceDb.post.findMany({
        where: {
          ...(includeUnpublished ? {} : { status: 'published' })
        },
        include: {
          author: true,
          tags: true,
          comments: {
            take: 5,
            include: { author: true }
          }
        },
        take: limitPerUser * 100 // Limite globale
      })
      
      for (const post of posts) {
        // S'assurer que l'auteur existe
        await targetDb.user.upsert({
          where: { id: post.author.id },
          update: {},
          create: {
            id: post.author.id,
            email: post.author.email,
            name: post.author.name,
            role: post.author.role
          }
        })
        
        // Cr√©er le post
        await targetDb.post.upsert({
          where: { id: post.id },
          update: {
            title: post.title,
            content: post.content,
            status: post.status,
            updatedAt: new Date()
          },
          create: {
            id: post.id,
            title: post.title,
            content: post.content,
            status: post.status,
            authorId: post.author.id,
            createdAt: post.createdAt
          }
        })
      }
      
      console.log(\`\${posts.length} posts synchronis√©s\`)
      
    } catch (error) {
      console.error('Erreur sync posts:', error)
      throw error
    }
  }
  
  static getConnection(environment) {
    // Retourner la connexion appropri√©e selon l'environnement
    switch (environment) {
      case 'development':
        return prisma // Connection locale
      case 'staging':
        return new PrismaClient({
          datasources: { db: { url: process.env.STAGING_DATABASE_URL } }
        })
      case 'production':
        return new PrismaClient({
          datasources: { db: { url: process.env.PRODUCTION_DATABASE_URL } }
        })
      default:
        throw new Error(\`Environnement inconnu: \${environment}\`)
    }
  }
}</code></pre>
      </div>
      
      <h3>4. Monitoring et Alertes</h3>
      <p>Syst√®me de surveillance des op√©rations de base de donn√©es.</p>
      
      <div class="code-example">
        <pre><code>// lib/db-monitoring.js
import { Webhook } from '@slack/webhook'

export class DatabaseMonitoring {
  constructor() {
    this.slackWebhook = new Webhook(process.env.SLACK_WEBHOOK_URL)
    this.metrics = {
      connectionPool: { active: 0, idle: 0, total: 0 },
      queryPerformance: { slow: 0, total: 0 },
      errors: { total: 0, recent: [] }
    }
  }
  
  async checkConnectionHealth() {
    try {
      const start = Date.now()
      await prisma.$queryRaw\`SELECT 1\`
      const duration = Date.now() - start
      
      if (duration > 5000) { // Plus de 5 secondes
        await this.sendAlert('WARN', 'Connexion BDD lente', {
          duration: \`\${duration}ms\`,
          threshold: '5000ms'
        })
      }
      
      return { healthy: true, responseTime: duration }
      
    } catch (error) {
      await this.sendAlert('ERROR', 'Connexion BDD √©chou√©e', error)
      return { healthy: false, error: error.message }
    }
  }
  
  async monitorQueryPerformance(query, duration, params = []) {
    this.metrics.queryPerformance.total++
    
    if (duration > 2000) { // Plus de 2 secondes
      this.metrics.queryPerformance.slow++
      
      await this.logSlowQuery({
        query: query.substring(0, 200),
        duration,
        params: params.length,
        timestamp: new Date().toISOString()
      })
      
      // Alert si trop de requ√™tes lentes
      const slowRatio = this.metrics.queryPerformance.slow / 
                       this.metrics.queryPerformance.total
      
      if (slowRatio > 0.1) { // Plus de 10% de requ√™tes lentes
        await this.sendAlert('WARN', 'Trop de requ√™tes lentes', {
          slowQueries: this.metrics.queryPerformance.slow,
          totalQueries: this.metrics.queryPerformance.total,
          ratio: \`\${(slowRatio * 100).toFixed(2)}%\`
        })
      }
    }
  }
  
  async logSlowQuery(queryInfo) {
    console.warn('Requ√™te lente d√©tect√©e:', queryInfo)
    
    // Enregistrer en base pour analyse
    try {
      await prisma.slow_query_log.create({
        data: {
          query: queryInfo.query,
          duration: queryInfo.duration,
          params_count: queryInfo.params,
          created_at: new Date(queryInfo.timestamp)
        }
      })
    } catch (error) {
      console.error('Erreur log requ√™te lente:', error)
    }
  }
  
  async sendAlert(level, message, details = {}) {
    const color = {
      'INFO': '#36a64f',
      'WARN': '#ff9900',
      'ERROR': '#ff0000'
    }[level] || '#cccccc'
    
    const slackMessage = {
      text: \`\${level}: \${message}\`,
      attachments: [{
        color: color,
        fields: [
          {
            title: 'Environnement',
            value: process.env.NODE_ENV,
            short: true
          },
          {
            title: 'Timestamp',
            value: new Date().toISOString(),
            short: true
          },
          ...Object.entries(details).map(([key, value]) => ({
            title: key,
            value: typeof value === 'object' ? JSON.stringify(value) : value,
            short: true
          }))
        ]
      }]
    }
    
    try {
      await this.slackWebhook.send(slackMessage)
    } catch (error) {
      console.error('Erreur envoi alerte Slack:', error)
    }
  }
  
  startMonitoring() {
    // V√©rification de sant√© toutes les 5 minutes
    setInterval(() => {
      this.checkConnectionHealth()
    }, 5 * 60 * 1000)
    
    // Reset des m√©triques toutes les heures
    setInterval(() => {
      this.metrics.queryPerformance = { slow: 0, total: 0 }
    }, 60 * 60 * 1000)
  }
}</code></pre>
      </div>
    `,

    practicalExample: {
      title: 'Pipeline de Migration Automatis√©',
      code: `// scripts/deploy-pipeline.js
import { MigrationManager } from './migration-manager'
import { BackupManager } from './backup-manager'
import { DataSynchronizer } from './data-sync'
import { DatabaseMonitoring } from '../lib/db-monitoring'

export class DeploymentPipeline {
  constructor(environment) {
    this.environment = environment
    this.backupManager = new BackupManager()
    this.monitoring = new DatabaseMonitoring()
  }
  
  async executePipeline() {
    console.log(\`üöÄ D√©but du d√©ploiement vers \${this.environment}\`)
    
    try {
      // √âtape 1: V√©rifications pr√©-d√©ploiement
      await this.preDeploymentChecks()
      
      // √âtape 2: Sauvegarde si production
      if (this.environment === 'production') {
        console.log('üì¶ Cr√©ation de la sauvegarde...')
        await this.backupManager.createDatabaseBackup()
      }
      
      // √âtape 3: Tests de migration sur une copie
      if (this.environment === 'production') {
        console.log('üß™ Test de migration sur copie...')
        await this.testMigrationOnCopy()
      }
      
      // √âtape 4: D√©ploiement des migrations
      console.log('‚ö° D√©ploiement des migrations...')
      await MigrationManager.deployMigration(this.environment)
      
      // √âtape 5: V√©rifications post-d√©ploiement
      await this.postDeploymentChecks()
      
      // √âtape 6: Synchronisation des donn√©es si n√©cessaire
      if (this.environment === 'staging') {
        console.log('üîÑ Synchronisation des donn√©es...')
        await this.syncProductionData()
      }
      
      console.log('‚úÖ D√©ploiement termin√© avec succ√®s!')
      
    } catch (error) {
      console.error('‚ùå Erreur lors du d√©ploiement:', error)
      await this.handleDeploymentFailure(error)
      throw error
    }
  }
  
  async preDeploymentChecks() {
    // V√©rifier la sant√© de la base
    const health = await this.monitoring.checkConnectionHealth()
    if (!health.healthy) {
      throw new Error('Base de donn√©es non accessible')
    }
    
    // V√©rifier les migrations en attente
    const pendingMigrations = await this.checkPendingMigrations()
    console.log(\`Migrations en attente: \${pendingMigrations.length}\`)
    
    // V√©rifier l'espace disque
    await this.checkDiskSpace()
    
    console.log('‚úÖ V√©rifications pr√©-d√©ploiement OK')
  }
  
  async testMigrationOnCopy() {
    // Cr√©er une copie de test de la BDD
    const testDbName = \`test_migration_\${Date.now()}\`
    
    try {
      // Copier la structure et quelques donn√©es
      await this.createTestDatabase(testDbName)
      
      // Tester la migration
      await this.runMigrationTest(testDbName)
      
      console.log('‚úÖ Test de migration r√©ussi')
      
    } finally {
      // Nettoyer la base de test
      await this.cleanupTestDatabase(testDbName)
    }
  }
  
  async postDeploymentChecks() {
    // V√©rifier que l'application r√©pond
    const healthCheck = await fetch(\`\${process.env.APP_URL}/api/health\`)
    if (!healthCheck.ok) {
      throw new Error('Application non responsive apr√®s migration')
    }
    
    // V√©rifier l'int√©grit√© des donn√©es
    await this.checkDataIntegrity()
    
    // Tests de fum√©e
    await this.runSmokeTests()
    
    console.log('‚úÖ V√©rifications post-d√©ploiement OK')
  }
  
  async syncProductionData() {
    await DataSynchronizer.syncUserData('production', 'staging', {
      anonymize: true,
      includePasswords: false
    })
    
    await DataSynchronizer.syncPostsData('production', 'staging', {
      includeUnpublished: false,
      limitPerUser: 5
    })
  }
  
  async handleDeploymentFailure(error) {
    console.log('üîß Gestion de l\\'√©chec du d√©ploiement...')
    
    // Notifier l'√©quipe
    await this.monitoring.sendAlert('ERROR', '√âchec du d√©ploiement', {
      environment: this.environment,
      error: error.message,
      timestamp: new Date().toISOString()
    })
    
    // Rollback si en production
    if (this.environment === 'production') {
      console.log('‚è™ Rollback en cours...')
      await MigrationManager.rollbackMigration()
    }
  }
}

// Usage
const pipeline = new DeploymentPipeline('production')
pipeline.executePipeline().catch(console.error)`,
      explanation:
        "Ce pipeline automatise enti√®rement le processus de d√©ploiement avec sauvegarde, tests, et rollback automatique en cas d'erreur."
    },

    exercise: {
      question:
        'Quelle est la meilleure pratique pour les migrations en production ?',
      options: [
        'Appliquer directement les migrations',
        'Tester sur une copie puis sauvegarder avant application',
        'Faire les migrations manuellement',
        'Ignorer les migrations en production'
      ],
      correctAnswer: 1,
      explanation:
        'Il faut toujours tester les migrations sur une copie et cr√©er une sauvegarde avant de les appliquer en production pour pouvoir faire un rollback en cas de probl√®me.'
    },

    quiz: [
      {
        question: "Que signifie une migration 'zero-downtime' ?",
        options: [
          'Migration tr√®s rapide',
          'Migration sans arr√™t de service',
          'Migration automatique',
          'Migration r√©versible'
        ],
        correctAnswer: 1
      },
      {
        question:
          'Quelle fr√©quence est recommand√©e pour les sauvegardes automatiques ?',
        options: [
          'Une fois par mois',
          'Une fois par semaine',
          'Une fois par jour',
          'Plusieurs fois par jour'
        ],
        correctAnswer: 2
      }
    ],

    project: {
      title: 'Syst√®me de Migration Compl√®te',
      description:
        'Cr√©ez un syst√®me complet de gestion des migrations avec monitoring, alertes et rollback automatique.',
      initialCode: `// scripts/migration-system.js
export class MigrationSystem {
  constructor() {
    // Configuration initiale
  }
  
  // √Ä compl√©ter
  async planMigration(migrationName) {
    // Votre code ici
  }
  
  // √Ä compl√©ter
  async executeMigration(plan) {
    // Votre code ici
  }
  
  // √Ä compl√©ter
  async monitorMigration(migrationId) {
    // Votre code ici
  }
}`,
      solution: `// scripts/migration-system.js
import { MigrationManager } from './migration-manager'
import { BackupManager } from './backup-manager'
import { DatabaseMonitoring } from '../lib/db-monitoring'
import { EventEmitter } from 'events'

export class MigrationSystem extends EventEmitter {
  constructor() {
    super()
    this.backupManager = new BackupManager()
    this.monitoring = new DatabaseMonitoring()
    this.activeMigrations = new Map()
    this.migrationHistory = []
  }
  
  async planMigration(migrationName, options = {}) {
    const plan = {
      id: \`migration_\${Date.now()}\`,
      name: migrationName,
      environment: options.environment || 'development',
      strategy: options.strategy || 'standard', // standard, zero-downtime, blue-green
      steps: [],
      estimatedDuration: 0,
      risks: [],
      rollbackPlan: null,
      createdAt: new Date()
    }
    
    // Analyser la migration
    await this.analyzeMigration(plan)
    
    // Planifier les √©tapes
    await this.planSteps(plan, options)
    
    // √âvaluer les risques
    await this.assessRisks(plan)
    
    // Cr√©er le plan de rollback
    plan.rollbackPlan = await this.createRollbackPlan(plan)
    
    console.log(\`Plan de migration cr√©√©: \${plan.id}\`)
    this.emit('migrationPlanned', plan)
    
    return plan
  }
  
  async executeMigration(plan) {
    const migrationId = plan.id
    
    try {
      console.log(\`üöÄ D√©but de l'ex√©cution: \${migrationId}\`)
      
      // Marquer comme active
      this.activeMigrations.set(migrationId, {
        ...plan,
        status: 'running',
        startedAt: new Date(),
        currentStep: 0,
        completedSteps: []
      })
      
      this.emit('migrationStarted', migrationId)
      
      // Ex√©cuter chaque √©tape
      for (let i = 0; i < plan.steps.length; i++) {
        const step = plan.steps[i]
        console.log(\`√âtape \${i + 1}/\${plan.steps.length}: \${step.name}\`)
        
        // Mettre √† jour le statut
        const migration = this.activeMigrations.get(migrationId)
        migration.currentStep = i
        
        this.emit('migrationProgress', {
          migrationId,
          step: i + 1,
          total: plan.steps.length,
          stepName: step.name
        })
        
        // Ex√©cuter l'√©tape
        await this.executeStep(step, migration)
        
        // Marquer comme compl√©t√©e
        migration.completedSteps.push({
          ...step,
          completedAt: new Date()
        })
        
        // Point de contr√¥le
        if (step.checkpoint) {
          await this.createCheckpoint(migrationId, i)
        }
      }
      
      // Marquer comme termin√©e
      const migration = this.activeMigrations.get(migrationId)
      migration.status = 'completed'
      migration.completedAt = new Date()
      
      console.log(\`‚úÖ Migration \${migrationId} termin√©e avec succ√®s\`)
      this.emit('migrationCompleted', migrationId)
      
      // Archiver
      this.migrationHistory.push(migration)
      this.activeMigrations.delete(migrationId)
      
      return { success: true, migrationId }
      
    } catch (error) {
      console.error(\`‚ùå Erreur migration \${migrationId}:\`, error)
      
      await this.handleMigrationError(migrationId, error)
      this.emit('migrationFailed', { migrationId, error })
      
      throw error
    }
  }
  
  async monitorMigration(migrationId) {
    const migration = this.activeMigrations.get(migrationId)
    if (!migration) {
      throw new Error(\`Migration non trouv√©e: \${migrationId}\`)
    }
    
    return {
      id: migrationId,
      status: migration.status,
      progress: {
        current: migration.currentStep + 1,
        total: migration.steps.length,
        percentage: Math.round(((migration.currentStep + 1) / migration.steps.length) * 100)
      },
      duration: Date.now() - migration.startedAt.getTime(),
      currentStep: migration.steps[migration.currentStep]?.name,
      completedSteps: migration.completedSteps.length,
      estimatedTimeRemaining: this.calculateRemainingTime(migration)
    }
  }
  
  async analyzeMigration(plan) {
    // Analyser la complexit√© de la migration
    const complexity = await this.assessComplexity(plan.name)
    plan.complexity = complexity
    
    // Estimer la dur√©e
    plan.estimatedDuration = this.estimateDuration(complexity)
    
    console.log(\`Analyse: complexit√© \${complexity}, dur√©e estim√©e \${plan.estimatedDuration}ms\`)
  }
  
  async planSteps(plan, options) {
    const steps = []
    
    // √âtapes standard
    if (plan.environment === 'production') {
      steps.push({
        name: 'V√©rifications pr√©-migration',
        type: 'validation',
        action: 'preChecks',
        checkpoint: true
      })
      
      steps.push({
        name: 'Cr√©ation de sauvegarde',
        type: 'backup',
        action: 'createBackup',
        checkpoint: true
      })
      
      if (options.testFirst) {
        steps.push({
          name: 'Test sur copie',
          type: 'test',
          action: 'testOnCopy',
          checkpoint: false
        })
      }
    }
    
    steps.push({
      name: 'Application de la migration',
      type: 'migration',
      action: 'applyMigration',
      checkpoint: true
    })
    
    steps.push({
      name: 'V√©rifications post-migration',
      type: 'validation',
      action: 'postChecks',
      checkpoint: false
    })
    
    plan.steps = steps
  }
  
  async executeStep(step, migration) {
    const startTime = Date.now()
    
    try {
      switch (step.action) {
        case 'preChecks':
          await this.monitoring.checkConnectionHealth()
          break
          
        case 'createBackup':
          await this.backupManager.createDatabaseBackup()
          break
          
        case 'testOnCopy':
          await this.testMigrationOnCopy()
          break
          
        case 'applyMigration':
          await MigrationManager.deployMigration(migration.environment)
          break
          
        case 'postChecks':
          await this.validateMigration()
          break
          
        default:
          throw new Error(\`Action inconnue: \${step.action}\`)
      }
      
      const duration = Date.now() - startTime
      console.log(\`√âtape '\${step.name}' termin√©e en \${duration}ms\`)
      
    } catch (error) {
      console.error(\`Erreur √©tape '\${step.name}':\`, error)
      throw error
    }
  }
  
  async handleMigrationError(migrationId, error) {
    const migration = this.activeMigrations.get(migrationId)
    migration.status = 'failed'
    migration.error = error.message
    migration.failedAt = new Date()
    
    // Notifier
    await this.monitoring.sendAlert('ERROR', 'Migration √©chou√©e', {
      migrationId,
      error: error.message,
      step: migration.currentStep
    })
    
    // Rollback automatique si configur√©
    if (migration.environment === 'production' && migration.rollbackPlan) {
      console.log('üîÑ Rollback automatique...')
      await this.executeRollback(migration.rollbackPlan)
    }
  }
  
  async createRollbackPlan(plan) {
    return {
      id: \`rollback_\${plan.id}\`,
      migrationId: plan.id,
      steps: [
        {
          name: 'Arr√™t de l\\'application',
          action: 'stopApp'
        },
        {
          name: 'Restauration de la sauvegarde',
          action: 'restoreBackup'
        },
        {
          name: 'Red√©marrage de l\\'application',
          action: 'startApp'
        }
      ]
    }
  }
  
  calculateRemainingTime(migration) {
    const elapsed = Date.now() - migration.startedAt.getTime()
    const progress = (migration.currentStep + 1) / migration.steps.length
    
    if (progress === 0) return migration.estimatedDuration
    
    return Math.round((elapsed / progress) - elapsed)
  }
  
  // Getters pour monitoring
  getActiveMigrations() {
    return Array.from(this.activeMigrations.values())
  }
  
  getMigrationHistory() {
    return this.migrationHistory
  }
  
  getMigrationStats() {
    const total = this.migrationHistory.length
    const successful = this.migrationHistory.filter(m => m.status === 'completed').length
    const failed = total - successful
    
    return {
      total,
      successful,
      failed,
      successRate: total > 0 ? (successful / total) * 100 : 0
    }
  }
}`
    }
  }
}

export default lesson3
